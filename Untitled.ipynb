{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7883cb33e389>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mwebp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwebp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mairline\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"bold flightAirline\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mflight_number\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"flightNumber\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;31m#duration =(soup.find(\"span\", \"duration bold \")).text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "table = []\n",
    "flights = ['6E171','6E5335','6E993','6E167','6E179','6E181','6E5339','6E223','6E957','6E189'],'6E755','6E191','6E129','6E843','6E197','6E185','6E665','6E155','I5314','I5716','I5332','I5482','AI349','AI887','AI665','AI678','AI865','AI315','AI317','AI636','AI102','AI441','AI24','AI624','AI805','AI191','AI863','G82501','G8338','G8530','G8334','G8336','G8640','G8446','G8429','G8544','SG8287','SG8153','SG8701','SG8723','SG8911','SG8161','SG8709','SG8169','SG8715','SG8159','UK975','UK923','UK943','UK963','UK927','UK995','UK945','UK993','UK941','UK955','UK977','UK985','UK953','UK981','UK967','6E2625','6E2135','6E2562','6E2132','6E2228','6E5032','6E5022','6E2032','6E2988','6E2783','6E2808','6E2716','6E2305','6E2289','6E2484','I52878','I5737','I5741','I5722','AI804','AI505','AI501','AI503','AI87','AI173','AI802','G8116','G8117','G8120','G8118','SG8906','SG136','SG192','SG198','SG8720','UK110','UK812','UK816','UK820','UK814','UK818','6E456','6E5322','6E5324','6E424','6E734','6E346','6E414','6E361','6E5331','6E6449','6E5348','6E6794','6E849','I5303','I5304','I5306','I5334','AI640','AI604','AI507','AI608','AI610','G8418','G8395','G8320','G8526','SG456','SG438','SG6351','UK858','UK846','UK852','UK864','UK854','UK850','UK866']\n",
    "for mm in range(11,13):\n",
    "    for dd in range(1,32):\n",
    "        for flight in flights: \n",
    "            url = \"https://airportinfo.live/flight/\"+flight+\"?d=2019-\"+str(mm)+\"-\"+str(dd)\n",
    "            req = requests.get(url)\n",
    "            webp = req.text\n",
    "            soup = BeautifulSoup(webp, 'html.parser')\n",
    "            airline =(soup.find(\"span\", \"bold flightAirline\")).text\n",
    "            flight_number =(soup.find(\"span\", \"flightNumber\")).text\n",
    "            #duration =(soup.find(\"span\", \"duration bold \")).text\n",
    "            distance =(soup.find(\"span\", \"duration_distance\")).text\n",
    "            distance = distance.split()[3] \n",
    "            from_city =(soup.find(\"span\", \"bold from_city\")).text\n",
    "            to_city =(soup.find(\"span\", \"bold to_city\")).text\n",
    "            times = soup.findAll(\"div\",\"important_time\")\n",
    "            times_text = [t.text for t in times]\n",
    "            date = url[-10:]\n",
    "            new_date = date.split('-')\n",
    "            year = new_date[0][-4:]\n",
    "            month = new_date[1]\n",
    "            day = new_date[2]\n",
    "            row = []\n",
    "            row.append(airline)\n",
    "            row.append(flight_number)\n",
    "            row.append(from_city)\n",
    "            row.append(to_city)\n",
    "            row.append(distance)\n",
    "            #row.append(duration)\n",
    "            row.append(day)\n",
    "            row.append(month)\n",
    "            row.append(year)\n",
    "            row = row + times_text\n",
    "            table.append(row)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for dd in range(1,32):\n",
    "        url = \"https://airportinfo.live/flight/\"+flight+\"?d=2020-1\"+\"-\"+str(dd)\n",
    "        req = requests.get(url)\n",
    "        webp = req.text\n",
    "        soup = BeautifulSoup(webp, 'html.parser')\n",
    "        airline =(soup.find(\"span\", \"bold flightAirline\")).text\n",
    "        flight_number =(soup.find(\"span\", \"flightNumber\")).text\n",
    "        #duration =(soup.find(\"span\", \"duration bold \")).text\n",
    "        distance =(soup.find(\"span\", \"duration_distance\")).text\n",
    "        distance = distance.split()[3] \n",
    "        from_city =(soup.find(\"span\", \"bold from_city\")).text\n",
    "        to_city =(soup.find(\"span\", \"bold to_city\")).text\n",
    "        times = soup.findAll(\"div\",\"important_time\")\n",
    "        times_text = [t.text for t in times]\n",
    "        date = url[-10:]\n",
    "        new_date = date.split('-')\n",
    "        year = new_date[0][-4:]\n",
    "        month = new_date[1]\n",
    "        day = new_date[2]\n",
    "        row = []\n",
    "        row.append(airline)\n",
    "        row.append(flight_number)\n",
    "        row.append(from_city)\n",
    "        row.append(to_city)\n",
    "        row.append(distance)\n",
    "        #row.append(duration)\n",
    "        row.append(day)\n",
    "        row.append(month)\n",
    "        row.append(year)\n",
    "        row = row + times_text\n",
    "        table.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_arr = np.array(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(tab_arr, columns = ['Airline','Flight Number','Origin Airport','Destination Airport','Distance(Km)','DD','MM','YY','Scheduled Departure','Scheduled Arrival','Actual Departure','Actual Arrival'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
